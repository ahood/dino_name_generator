{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56acf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and auxiliary stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "with open('dino_first_letter_freq_dist.csv') as f:\n",
    "    first_letter, frequency = zip(*[\n",
    "        line.split(',') for line in f.read().split()\n",
    "    ])\n",
    "frequency = [float(f) for f in frequency]\n",
    "\n",
    "with open('dino_model_vocab.json') as f:\n",
    "    vocab = json.load(f)\n",
    "token_to_index = {v:k for k,v in enumerate(vocab)}\n",
    "index_to_token = {k:v for k,v in enumerate(vocab)}\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.RNN(len(vocab), hidden_size)\n",
    "        self.linear1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # note we are going to output logits and use CrossEntropyLoss,\n",
    "        # so no need to define softmax here\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        # input is a single one-hot encoded token, in the form of a 2d\n",
    "        # array with first dimension 1 and second dimension the vocab size\n",
    "        hidden, _ = self.rnn(input, hidden) # the two outputs are equal the way we have things set up; not sure of different in general though\n",
    "        x = self.dropout(hidden)\n",
    "        x = self.linear1(x)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.linear2(x)\n",
    "        return logits, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "rnn = torch.load('dino_rnn.pth')\n",
    "\n",
    "def letterTensor(letter):\n",
    "    onehot = np.zeros((1, len(vocab)))\n",
    "    index = token_to_index[letter]\n",
    "    onehot[0, index] = 1\n",
    "    return torch.from_numpy(np.expand_dims(onehot, axis=1)).float() # numpy default is float64 but torch wants float32\n",
    "\n",
    "def generate(maxlen=30):\n",
    "    # first generate first letter\n",
    "    x = random.choices(first_letter, weights=frequency, k=1)[0]\n",
    "    with torch.no_grad():\n",
    "        hidden = rnn.initHidden()\n",
    "        generated = ''\n",
    "\n",
    "        while x != '\\n':\n",
    "            # append this letter to the generated string\n",
    "            generated += x\n",
    "            # convert x to an input tensor\n",
    "            letter_tensor = letterTensor(x)\n",
    "            # generate logits and hidden\n",
    "            logits, hidden = rnn(letter_tensor[[0]], hidden)\n",
    "            # from the logits, compute probabilities\n",
    "            probs = nn.Softmax(dim=2)(logits).flatten()\n",
    "            # pull next letter from this probability distribution\n",
    "            x = random.choices(vocab, weights=probs, k=1)[0]\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1de3da3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bukpnoleon'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47e00563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "button = widgets.Button(\n",
    "    description='Generate',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "\n",
    ")\n",
    "out = widgets.Output()\n",
    "def onclick(change):\n",
    "    out.clear_output()\n",
    "    generated = generate()\n",
    "    with out:\n",
    "        display(generated)\n",
    "\n",
    "button.on_click(onclick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0290c81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f77227b09b4bac81e98417876380e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(description='Generate', style=ButtonStyle()), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([\n",
    "    button,\n",
    "    out\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b951a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
